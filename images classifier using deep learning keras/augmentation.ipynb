{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 142 images belonging to 2 classes.\n",
      "Found 143 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('datas/train', target_size=(150, 150),\n",
    "                                                    batch_size=batch_size,class_mode='binary')  \n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( 'datas/validation',target_size=(150, 150),\n",
    "                                                        batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 90s 719ms/step - loss: 0.0072 - acc: 0.9985 - val_loss: 2.0592 - val_acc: 0.8415\n",
      "Epoch 2/25\n",
      "125/125 [==============================] - 91s 724ms/step - loss: 0.0249 - acc: 0.9975 - val_loss: 1.5321 - val_acc: 0.8615\n",
      "Epoch 3/25\n",
      "125/125 [==============================] - 92s 733ms/step - loss: 0.0047 - acc: 0.9995 - val_loss: 1.3333 - val_acc: 0.8780\n",
      "Epoch 4/25\n",
      "125/125 [==============================] - 91s 728ms/step - loss: 1.9209e-04 - acc: 1.0000 - val_loss: 1.9785 - val_acc: 0.8363\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - 90s 723ms/step - loss: 0.0184 - acc: 0.9975 - val_loss: 1.9758 - val_acc: 0.8679\n",
      "Epoch 6/25\n",
      "125/125 [==============================] - 90s 724ms/step - loss: 0.0103 - acc: 0.9980 - val_loss: 3.2420 - val_acc: 0.7645\n",
      "Epoch 7/25\n",
      "125/125 [==============================] - 91s 725ms/step - loss: 0.0194 - acc: 0.9964 - val_loss: 1.7592 - val_acc: 0.8478\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - 90s 720ms/step - loss: 3.8370e-04 - acc: 1.0000 - val_loss: 2.1533 - val_acc: 0.8199\n",
      "Epoch 9/25\n",
      "125/125 [==============================] - 91s 727ms/step - loss: 0.0094 - acc: 0.9985 - val_loss: 1.7541 - val_acc: 0.8539\n",
      "Epoch 10/25\n",
      "125/125 [==============================] - 91s 726ms/step - loss: 0.0057 - acc: 0.9995 - val_loss: 1.7256 - val_acc: 0.8465\n",
      "Epoch 11/25\n",
      "125/125 [==============================] - 91s 725ms/step - loss: 3.4555e-04 - acc: 1.0000 - val_loss: 2.0664 - val_acc: 0.8539\n",
      "Epoch 12/25\n",
      " 40/125 [========>.....................] - ETA: 53s - loss: 2.0633e-07 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=2000 // batch_size, \n",
    "                    epochs=25, validation_data=validation_generator,validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
